---
output:
  html_document:
    toc: true
    number_sections: false
    toc_depth: 3
author: "Carl Beuchel"
date: "`r format(Sys.time(), '%d %B, %Y')`"
editor_options: 
  chunk_output_type: console
---

```{r knitr, cache = F, results = "hide", echo = F ,include = T}
# start with a clean workspace
rm(list=ls())
gc()

# Set the global knitr options
knitr::opts_chunk$set(cache = F, results = "hide", echo = F ,include = T)

# what should the output file be called?
filename = "STEP 2: Zero-inflated data exploration"
```

# `r filename`
***
This script is a small data simulation to help figure out an appropriate data transformation withouth loosing too much statistical power in the subsequent regression analyses.

```{r initiate, message=FALSE, warning=T}
# choose correct working directory
r_on_server <- T
if (r_on_server == T) {
  basicpath <- "/net/ifs1/san_projekte/projekte/"
} else {
  basicpath <- "/mnt/ifs1_projekte/"
}
setwd(basicpath)

# set working directory
pathwd <-
  paste0(
    basicpath,
    "genstat/02_projekte/1703_ge_metab_a1_b3_sorbs/171124_ZeroInflatedDataSim"
  )
setwd(pathwd)

# get additional functions from Holger Kirstens newest RProfile file
newest_rprofile <-
  function(designation = paste0(basicpath, "genstat/07_programme/rtools/RProfile_hk/")) {
    files <- list.files(designation)
    RProfiles <- files[grep("Rprofile_hk_", files)]
    newest_RProfile <- tail(sort(RProfiles), n = 1)
    suppressPackageStartupMessages(source(paste0(designation, newest_RProfile)))
  }
newest_rprofile()

# start time measurement, define alternative package directory, define start codes for external start of the script
if (r_on_server == F) {
  initializeSkript(myfilename = filename, computer = "forostar") # enter which server you are on
} else
  initializeSkript(myfilename = filename, computer = "local")

# Packages
for (i in c(
  "knitr",
  "data.table",
  "MASS",
  "ggplot2",
  "scales"
)) {
  suppressPackageStartupMessages(library(i, character.only = TRUE))
}
```

## Data simulation and setup

```{r load}
# load the simuation results
all.scenarios <- fread("/mnt/ifs1_projekte/genstat/02_projekte/1703_ge_metab_a1_b3_sorbs/171124_ZeroInflatedDataSim/results/171207_SimulationResults.csv")
```

### Additional Functions

```{r add.func}
# Multiple plot function
#
# ggplot objects can be passed in ..., or to plotlist (as a list of ggplot objects)
# - cols:   Number of columns in layout
# - layout: A matrix specifying the layout. If present, 'cols' is ignored.
#
# If the layout is something like matrix(c(1,2,3,3), nrow=2, byrow=TRUE),
# then plot 1 will go in the upper left, 2 will go in the upper right, and
# 3 will go all the way across the bottom.
#
multiplot <- function(..., plotlist=NULL, file, cols=1, layout=NULL) {
  library(grid)

  # Make a list from the ... arguments and plotlist
  plots <- c(list(...), plotlist)

  numPlots = length(plots)

  # If layout is NULL, then use 'cols' to determine layout
  if (is.null(layout)) {
    # Make the panel
    # ncol: Number of columns of plots
    # nrow: Number of rows needed, calculated from # of cols
    layout <- matrix(seq(1, cols * ceiling(numPlots/cols)),
                    ncol = cols, nrow = ceiling(numPlots/cols))
  }

 if (numPlots==1) {
    print(plots[[1]])

  } else {
    # Set up the page
    grid.newpage()
    pushViewport(viewport(layout = grid.layout(nrow(layout), ncol(layout))))

    # Make each plot, in the correct location
    for (i in 1:numPlots) {
      # Get the i,j matrix positions of the regions that contain this subplot
      matchidx <- as.data.frame(which(layout == i, arr.ind = TRUE))

      print(plots[[i]], vp = viewport(layout.pos.row = matchidx$row,
                                      layout.pos.col = matchidx$col))
    }
  }
}

# create a -log10 transformation for scales
minuslog10_trans <- function() trans_new("minuslog10", function(x) -log10(x), function(x) 10(-x))

# theme from 
apatheme = theme_bw()+
  theme(panel.grid.major=element_blank(),
        panel.grid.minor=element_blank(),
        panel.border=element_blank(),
        axis.line=element_line(),
        text=element_text(family='Times'),
        legend.position='none')

```

## Exploratory plots

There are a few descisions that I need to make:
 - Bereiche or Quantile?
 - Best number of categories?
 - Performance compared with dichotomized glm?
 - Performance compared with Rank correlation?

### Performance of dichotomized metabolites vs. different number of categories in proportional odds model

Our best guess was, that grouping the metabolites into more categories than just 2 would result in the retaining of information and thus statistical power. These plots are supposed to illustrate the comparison between dichotomization and different versions of the proportional odds approach.

For the proportional odds model, the number of categories (`categnum`) and the way the categories were established (`categart`) vary. In this simulation, `r unique(all.scenarios$categnum)` were the number of categories tested.

For the data simulation, the parameters were the percentage of inflated zero-values (`proz0`) and the effekt size (`effekt`) varied. For each scenario, 5000 sampels were drawn. Each scenario was computed 1000 times. 

```{r question.1}
# First question: Dicho vs Logit
# plot all dicho vs. prop odds pvals
p1 <- ggplot(all.scenarios, aes(-log10(dicho.pval),
                                -log10(logit.pval),
                                col = factor(proz0),
                                pch = categart,
                                size = categnum,
                                alpha = rev(categnum))) + 
  geom_point() +
  geom_abline(intercept = 0, slope = 1, lty = 2) + 
  facet_wrap(~effekt , scales = "free") + 
  theme_minimal()

p1

# plot mean (over realizations) dicho vs. prop odds pvals
# über realisationen mitteln für Übersichtlichkeit
test.1 <- all.scenarios[, lapply(.SD, mean), by = .(effekt, proz0, categart, categnum)]
p2 <- ggplot(test.1, aes(x = -log10(dicho.pval),
                         y = -log10(logit.pval),
                         col = factor(proz0),
                         pch = categart,
                         size = categnum,
                         alpha = rev(categnum))) + 
  geom_point() +
  geom_abline(intercept = 0, slope = 1, lty = 2) + 
  facet_wrap(~effekt , scales = "free") + 
  theme_minimal()

p2

# same as p2 but with different symbols etc.
p2.5 <- ggplot(test.1, aes(-log10(dicho.pval),
                   -log10(logit.pval),
                   col = categnum,
                   pch = categart,
                   size = factor(proz0),
                   alpha = rev(factor(proz0)))) +
  geom_point() +
  facet_wrap(~effekt, scales = "free") +
  scale_x_continuous(breaks = pretty_breaks(4)) +
  scale_y_continuous(breaks = pretty_breaks(4)) +
  geom_abline(intercept = 0, slope = 1, lty = 2) +
  theme_minimal() + 
  scale_color_distiller(palette="Spectral") +
  scale_alpha_manual(values = c(0.3, 0.5, 0.9)) + 
  theme(panel.grid.major=element_blank(),
         panel.grid.minor=element_blank(),
         panel.border=element_blank(),
         axis.line=element_line(),
         text=element_text(family='Times'),
         legend.position ="right")

p2.5

# number of categories as deciding factor
kable(all.scenarios[linmod.pval <= 0.05, sum(logit.pval <= 0.05), by = .(categart,categnum)])
kable(all.scenarios[linmod.pval <= 0.05, sum(dicho.pval <= 0.05), by = .(categart,categnum)])

# plot mean (over realizations) linmod vs. prop odds pvals
# how does logit model compare to linmod?
p3 <- ggplot(test.1, aes(x = -log10(linmod.pval),
                         y = -log10(logit.pval),
                         col = factor(proz0),
                         pch = categart,
                         size = categnum,
                         alpha = rev(categnum))) + 
  geom_point() +
  geom_abline(intercept = 0, slope = 1, lty = 2) + 
  facet_wrap(~effekt , scales = "free") + 
  theme_minimal()

p3
```

```{r question.2}
# second question: what number of categories is optimal?
# plot -log10(Pwert) against number of categories
p4 <- ggplot(test.1,
             aes(x = categnum,
                 y = -log10(logit.pval),
                 pch = categart,
                 color = factor(proz0))) +
  facet_wrap(~ effekt, scale = "free") +
  geom_smooth(aes(group = paste(factor(proz0), categart), lty = categart), alpha = 0.2, fullrange=T, span = 1.5) +
  geom_point(size = 2.5) +
  theme_minimal()

p4
```

```{r question.3}
# third question: Bereiche oder Quantile
# plot bereiche ~ quantile pvals
test.2 <- dcast.data.table(data = test.1, formula = effekt + proz0 + categnum ~ categart, value.var = "logit.pval")
p5 <- ggplot(test.2,
       aes(x = -log10(bereiche),
           y = -log10(quantile),
           color = categnum,
           pch = as.factor(proz0))) +
  facet_wrap(~effekt, scale = "free") + 
  geom_point(alpha = 0.7) + 
  geom_abline(intercept = 0, slope = 1) + 
  scale_color_distiller(palette="Spectral") + 
  scale_alpha_manual(values = c(0.3,0.9))

p5
```

```{r question.4}
# comparison to rank
# scatterplot
p6 <- ggplot(test.1, aes(x = -log10(pearson.cor.pval),
                         y = -log10(logit.pval),
                         col = factor(proz0),
                         pch = categart,
                         size = categnum,
                         alpha = rev(categnum))) + 
  geom_point() +
  geom_abline(intercept = 0, slope = 1, lty = 2) + 
  facet_wrap(~effekt , scales = "free") + 
  theme_minimal()

p6

# boxplot
test.3 <- melt(data = all.scenarios,
               id.vars = c("effekt", "proz0", "categart", "categnum"),
               measure.vars = c("logit.pval", "dicho.pval", "linmod.pval", "pearson.cor.pval"))

# outer loop for proz0
lapply(unique(all.scenarios$proz0), function(y){
  
  # inner loop for effect size
  lapply(unique(all.scenarios$effekt), function(x){
    
    p7 <- ggplot(test.3[effekt == x & proz0 == y, ],
                 aes(y = -log10(value),
                     x = as.factor(categnum),
                     fill = variable)) +
      geom_boxplot() + 
      coord_flip() +
      facet_wrap( ~ categart) + 
      ggtitle(label = "Boxplot of Pvalues",
              subtitle = paste0("Effect-size = ", x, " and zero-inflation by ", y, "%")) +
      theme_minimal() +
      scale_fill_brewer(palette = "Spectral")
    
    p7
  })
})
```

```{r question.5}
p8 <- ggplot(test.1,
       aes(x = linmod.beta,
           y = logit.beta,
           size = categnum,
           col = factor(effekt),
           pch = categart,
           alpha = rev(factor(proz0)))) +
  geom_point() +
  geom_abline(intercept = 0, slope = 1, lty = 2, col = "black") +
  # facet_wrap( ~ , scales = "fixed") +
  scale_color_brewer(palette = "Spectral") +
  scale_alpha_manual(values = c(0.3, 0.5, 0.9)) + 
  theme_minimal() + 
  theme(panel.grid.major=element_blank(),
         panel.grid.minor=element_blank(),
         panel.border=element_blank(),
         axis.line=element_line(),
         text=element_text(family='Times'),
         legend.position ="right")

p8

```

```{r save}
# write.table(x = all.scenarios,
#             file = paste0(pathwd, "/results/",
#                           format(Sys.time(), '%y%m%d'),
#                           "_SimulationResults.csv"),
#             sep = "\t", row.names = F)
```

```{r SessionInfo, echo=F, results='markup'}
sessionInfo()
```            