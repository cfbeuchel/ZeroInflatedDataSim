---
output:
  html_document:
    toc: true
    toc_float: 
      collapsed: false
      smooth_scroll: false
    number_sections: true
    toc_depth: 4
author: "Carl Beuchel"
date: "`r format(Sys.time(), '%d %B, %Y')`"
editor_options: 
  chunk_output_type: console
---

```{r knitr, cache = F, results = "hide", echo = F, warning = T}
# start with a clean workspace
rm(list=ls())
gc()

# Set the global knitr options
knitr::opts_chunk$set(cache = F, results = "hide", echo = F, include = T, message = T, warning = F)

# what should the output file be called?
filename = "STEP 2: Zero-inflated data with Zeros set to NA exploration"
```

# `r filename`
***
This script is a small data simulation to help figure out an appropriate data transformation withouth loosing too much statistical power in the subsequent regression analyses.

```{r initiate}
# define alternative package directory
r_on_server <- T # MANUAL EDIT! ARE YOU ON LOCAL R SESSION OR USING ONE OF THE IMISE SERVERS (E.G. FOROSTAR)?
if (r_on_server == T) {
  computer <- "forostar" # MANUAL EDIT! SEE THE FOLDER RIGHT BELOW FOR THE APPROPRIATE PACKAGE FOLDERS
  .libPaths(paste0("/net/ifs1/san_projekte/projekte/genstat/07_programme/rpackages/", computer))
}

# Packages for efficiently loading data
for (i in c(
  "knitr",
  "data.table",
  "MASS",
  "ggplot2",
  "scales",
  "CarlHelpR",
  "toolboxH"
)) {
  suppressPackageStartupMessages(library(i, character.only = TRUE))
}
```

# Data simulation and setup

```{r load}
# load the simuation results
newest.results <- newest_file(look_for = "SimulationResultsWithNAsForSTEP2", subfolder = "results", print_full = T)
all.scenarios <- fread(newest.results)
```

```{r question.1.2, results='markup'}
# plot mean (over realizations) dicho vs. prop odds pvals
# über realisationen mitteln für Übersichtlichkeit
test.1 <- all.scenarios[, lapply(.SD, mean), by = .(effekt, proz0, categart, categnum, batch.effect)]
```

## Additional comparisons

Comparing the results of the, always fit with zero-inflated data, prop-odds model fit with the, either fit to the full or zero-inflated data set, rank correlation and linear model results The boxplots compare the p-value distribution of all approaches. Since we discontinue to look at the differences of area vs. quantiles as a measure for the categories, we'll continue with only the range-based categories. 

```{r question.4.1.prep, results='markup'}
# define a general plot function
q_4 <- function(x,y) {
  p4 <- ggplot(test.1[categart == "bereiche", ], aes(x = -log10(get(x)),
                                                     y = -log10(get(y)),
                                                     col = factor(proz0),
                                                     pch = factor(batch.effect),
                                                     size = categnum,
                                                     alpha = rev(categnum))) + 
    geom_point() +
    ylab(y) +
    xlab(x) +
    geom_abline(intercept = 0, slope = 1, lty = 2) +
    scale_color_brewer(palette="Dark2") + 
    scale_alpha_continuous(range = c(0.3, 1)) +
    facet_wrap(~effekt , scales = "free") + 
    theme_carl() #+
    #theme(text = element_text(size=15))
  
  return(p4)
}

# when not looking at categorical data
q_5 <- function(x,y) {
  p5 <- ggplot(test.1[categart == "bereiche", ], aes(x = -log10(get(x)),
                                                     y = -log10(get(y)),
                                                     col = factor(effekt),
                                                     pch = factor(batch.effect),
                                                     size = proz0,
                                                     alpha = rev(proz0))) + 
    geom_point() +
    ylab(y) +
    xlab(x) +
    geom_abline(intercept = 0, slope = 1, lty = 2) +
    scale_color_brewer(palette="Dark2") + 
    scale_alpha_continuous(range = c(0.3, 1)) +
    facet_wrap(~effekt , scales = "free") + 
    theme_carl() +
    theme(text = element_text(size=15))
  
  return(p5)
}

```

### Linear model and Spearman's correlation

First we check what influence the zero-inflation has on the linear model and spearman correlation power. We plot p-values of both approaches with the full and the zero-inflated data against each other. We can see that the the linear model sufferes more from the loss of data even at 20% of zero-values, while the rank correlation starts to suffer visibly at 50% zero-inflation.

```{r question.4.0}
p5.0.1 <- q_5(x = "linmod.pval.full.data", y = "linmod.pval.zero.inflated")
p5.0.1

p5.0.2 <- q_5(x = "spearman.cor.pval.full.data", y = "spearman.cor.pval.zero.inflated")
p5.0.2
```

Comparing between approaches shows the expected advantage of a linear model over rank correlation for the full data set. Zero-inflating the data evens the performance out. The violated normality assumption of the linear model should be considered when choosing between the approaches. A non-parametric approach like Spearman's rank correlation seems like the choice of reason. 

```{r question.4.1}
p5.1.2 <- q_5(x = "spearman.cor.pval.full.data", y = "linmod.pval.full.data")
p5.1.2

p5.1.1 <- q_5(x = "spearman.cor.pval.zero.inflated", y = "linmod.pval.zero.inflated")
p5.1.1
```

```{r question.4.4, include = F, eval = F}
# boxplot
test.3 <- melt(data = all.scenarios,
               id.vars = c("effekt", "proz0", "categart", "categnum", "batch.effect"),
               measure.vars = c("logit.pval",
                                "dicho.pval",
                                "linmod.pval.zero.inflated",
                                "linmod.pval.full.data",
                                "spearman.cor.pval.zero.inflated",
                                "spearman.cor.pval.full.data",
                                "spearman.cor.pval.zero.inflated.transformed",
                                "linmod.pval.zero.inflated.transformed",
                                "linmod.pval.zero.inflated.transformed.rescaled"))

# outer loop for proz0
lapply(unique(all.scenarios$proz0), function(y){
  
  # inner loop for effect size
  lapply(unique(all.scenarios$effekt), function(x){
    
    p7 <- ggplot(test.3[effekt == x & proz0 == y, ],
                 aes(y = -log10(value),
                     x = as.factor(categnum),
                     fill = variable)) +
      geom_boxplot() + 
      coord_flip() +
      facet_wrap( ~ categart) + 
      ggtitle(label = "Boxplot of Pvalues",
              subtitle = paste0("Effect-size = ", x, " and zero-inflation by ", y, "%")) +
      theme_minimal() +
      scale_fill_brewer(palette = "Spectral")
    
    p7
  })
})
```

## Comparison of effect sizes between linear model and proportional odds model

Plotting the average effect sizes from the linear model and the prop-odds model reveal a drastic overestimation of effect size with increasing effect size in the data by the prop-odds model. Additionally, the zero-inflation seems to be influencig seems to be adding to to this overestimation while leading to an underestimation of the added effect in the linear model.

### Plot definition

```{r question.5}
# plot without -log10
p_8 <- function(x,y) {
  
  # define
  p8 <- ggplot(test.1[categart == "bereiche",],
               aes(x = get(x),
                   y = get(y),
                   size = proz0,
                   col = factor(effekt),
                   pch = factor(batch.effect),
                   alpha = rev(factor(proz0)))) +
    geom_point() +
    geom_abline(intercept = 0, slope = 1, lty = 2, col = "black") +
    # facet_wrap( ~ , scales = "fixed") +
    scale_color_brewer(palette = "Dark2") +
    ylab(y) +
    xlab(x) +
    scale_x_continuous(breaks = pretty_breaks(5)) +
    scale_y_continuous(breaks = pretty_breaks(5)) +
    scale_alpha_manual(values = c(0.3, 0.5, 0.7, 0.9)) + 
    theme_carl() +
    theme(text = element_text(size=15))
  
  # plot
  p8
}

# plot with -log10 of x & y
p_9 <- function(x,y) {
  
  # define
  p_9 <- ggplot(test.1[categart == "bereiche",],
                aes(x = -log10(get(x)),
                    y = -log10(get(y)),
                    size = proz0,
                    col = factor(effekt),
                    pch = factor(batch.effect),
                    alpha = rev(factor(proz0)))) +
    geom_point() +
    geom_abline(intercept = 0, slope = 1, lty = 2, col = "black") +
    # facet_wrap( ~ , scales = "fixed") +
    scale_color_brewer(palette = "Dark2") +
    ylab(y) +
    xlab(x) +
    scale_x_continuous(breaks = pretty_breaks(5)) +
    scale_y_continuous(breaks = pretty_breaks(5)) +
    scale_alpha_manual(values = c(0.3, 0.5, 0.7, 0.9)) + 
    theme_carl() +
    theme(text = element_text(size=15))
  
  # plot
  p_9
}
```

## Comparison of inverse-normal transformed zero-inflated data fit in lm()

### Effect-size plots

Check performance of inverse-normal transformed data against categorical and regular zero-inflated data. During the transformation the data is scaled to SD = 1. Rescaling them fixes the wrongly estimated meta for the non-zero-inflated INT transformed data

```{r int.betas}
# beta zero inflated lm vs. full lm
p_8(x = "linmod.beta.zero.inflated", y = "linmod.beta.full.data") +
  # xlim(c(0,0.4)) +
  # ylim(c(0,0.4)) +
  geom_vline(xintercept = c(0,0.01,0.02,0.05,0.1,0.3)) +
  geom_hline(yintercept = c(0,0.01,0.02,0.05,0.1,0.3))

# facetted
p_8(x = "linmod.beta.zero.inflated", y = "linmod.beta.full.data") +
  facet_wrap(~effekt , scales = "free") +
  ggtitle(label = "Beta estimate comparison", subtitle = "Zero-inflated data fit to linear model vs.\n full data fit with linear model")

```

### QQ plots of batch-effect ANOVA pre- and post-ComBat

#### For the mean data

```{r qq.plots.anova}
# pvals, beta, r² of transformed data based on batch 1/0
qq_conf(test.1$p.ANOVA.full.pre.ComBat, main = "QQplot full data before ComBat")
qq_conf(test.1$p.ANOVA.full.post.ComBat, main = "QQplot full data after ComBat")

# for zero-inflated data
qq_conf(test.1$p.ANOVA.zero.infl.pre.ComBat, main = "QQplot zero-inflated data before ComBat")
qq_conf(test.1$p.ANOVA.zero.infl.post.ComBat, main = "QQplot zero-inflated data after ComBat")

# for transformed data
qq_conf(test.1$p.ANOVA.zero.infl.post.ComBat.post.transformation, main = "QQplot zero-inflated & transformed data post ComBat")
```

#### For one example block w/ & w/o batch effects

```{r qq.plots.anove.example}
# check anova transformed
# full data
# with out 
qq_conf(all.scenarios[combat.run == 1, p.ANOVA.full.pre.ComBat],
        main = "QQ plot of ANOVA p-vals on full data\nwithout batch effects pre-ComBat")
qq_conf(all.scenarios[combat.run == 1, p.ANOVA.full.post.ComBat],
        main = "QQ plot of full data without batch effects pre-ComBat")

# with batch effect
qq_conf(all.scenarios[combat.run == 251, p.ANOVA.full.pre.ComBat],
        main = "QQ plot of full data with batch effects pre-ComBat")
qq_conf(all.scenarios[combat.run == 251, p.ANOVA.full.post.ComBat],
        main = "QQ plot of full data with batch effects pre-ComBat")

# without batch effect
qq_conf(all.scenarios[combat.run == 1, p.ANOVA.zero.infl.pre.ComBat],
        main = "QQ plot of zero-inflated data without batch effects pre-ComBat")
qq_conf(all.scenarios[combat.run == 1, p.ANOVA.zero.infl.post.ComBat],
        main = "QQ plot of zero-inflated data without batch effects post-ComBat")
qq_conf(all.scenarios[combat.run == 1, p.ANOVA.zero.infl.post.ComBat.post.transformation],
        main = "QQ plot of zero-inflated data without batch\neffects post-ComBat after INT")

# with batch-effect
qq_conf(all.scenarios[combat.run == 251, p.ANOVA.zero.infl.pre.ComBat],
        main = "QQ plot of zero-inflated data with batch effects pre-ComBat")
qq_conf(all.scenarios[combat.run == 251, p.ANOVA.zero.infl.post.ComBat],
        main = "QQ plot of zero-inflated data with batch effects post-ComBat")
qq_conf(all.scenarios[combat.run == 251, p.ANOVA.zero.infl.post.ComBat.post.transformation],
        main = "QQ plot of zero-inflated data with batch\neffects post-ComBat after INT")
```

# weird associations after INT

```{r int.batch.problem, eval = F, include = F}
# first get the combat.data from STEP1 for combat run 251

fit_plots <- function(combat.data, pdf_name){
# ComBated data
pdf(pdf_name, width = 14)
par(mfrow=c(1,2))
for (i in c(81, 85, 89, 93)) {
  
  # very ugly ad hoc indexing
  my.zero.infl <- c(0,20,50,80)
  dummy.index <- c(81, 85, 89, 93)
  my.dummy.index <- which(i == dummy.index)
  
  # set indices
  my.y <- paste0("y.0infl.", i)
  my.x <- paste0("x.", i)
  my.y.tr <- paste0("y.0infl.", i, ".transformed.rescaled")
  
  # fit lm
  lm <- lm(get(my.y) ~ get(my.x), data = combat.data)
  
  # coeffs for lm
  rmse <- round(sqrt(mean(resid(lm)^2)), 2)
  coefs <- coef(lm)
  b0 <- round(coefs[1], 2)
  b1 <- round(coefs[2],2)
  r2 <- round(summary(lm)$r.squared, 2)
  
  # Now build up the equation using constructs described in ?plotmath:
  eqn <- bquote(italic(beta) == .(b1) * "," ~~ 
                  r^2 == .(r2) * "," ~~ RMSE == .(rmse))
  
  
  lm.tr<- lm(get(my.y.tr) ~ get(my.x), data = combat.data)
  
  # coeffs for lm
  rmse.tr <- round(sqrt(mean(resid(lm.tr)^2)), 2)
  coefs.tr <- coef(lm.tr)
  b0.tr <- round(coefs.tr[1], 2)
  b1.tr <- round(coefs.tr[2],2)
  r2.tr <- round(summary(lm.tr)$r.squared, 2)
  
  # Now build up the equation using constructs described in ?plotmath:
  eqn.tr <- bquote(italic(beta) == .(b1.tr) * "," ~~ 
                  r^2 == .(r2.tr) * "," ~~ RMSE == .(rmse.tr))
  
  
  
  # untransformed
  combat.data[ , plot(get(my.x), get(my.y), main = paste0("Untransformed, ",
                                                          my.zero.infl[my.dummy.index],
                                                          "% zero-inflated data"),
                      sub = eqn, xlab = "", ylab = "")]
  combat.data[ , abline(lm, lwd = 3, col = "red")]

  # transformed
  combat.data[ , plot(get(my.x), get(my.y.tr), main = paste0("INT, ",
                                                          my.zero.infl[my.dummy.index],
                                                          "% zero-inflated data"),
                      sub = eqn.tr, xlab = "", ylab = "")]
  
  combat.data[ , abline(lm.tr, lwd = 3, col = "red")]

}
par(mfrow=c(1,1))
dev.off()
}

# create the data for combat run 251 twice! NEEDS TO BE DONE MANUALLY
# without ComBat but including the transformation
fit_plots(combat.data = combat.data, pdf_name = "zero_inflated_fit_NO_ComBat")

# with combat and transformation
fit_plots(combat.data = combat.data, pdf_name = "zero_inflated_fit_AFTER_ComBat")

```


```{r save}
# write.table(x = all.scenarios,
#             file = paste0(pathwd, "/results/",
#                           format(Sys.time(), '%y%m%d'),
#                           "_SimulationResults.csv"),
#             sep = "\t", row.names = F)
```

```{r SessionInfo, echo=F, results='markup'}
sessionInfo()
```            