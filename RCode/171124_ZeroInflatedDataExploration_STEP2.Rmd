---
output:
  html_document:
    toc: true
    toc_float: 
      collapsed: false
      smooth_scroll: false
    number_sections: true
    toc_depth: 4
author: "Carl Beuchel"
date: "`r format(Sys.time(), '%d %B, %Y')`"
editor_options: 
  chunk_output_type: console
---

```{r knitr, cache = F, results = "hide", echo = F, warning = T}
# start with a clean workspace
rm(list=ls())
gc()

# Set the global knitr options
knitr::opts_chunk$set(cache = F, results = "hide", echo = F, include = T, message = T, warning = F)

# what should the output file be called?
filename = "STEP 2: Zero-inflated data exploration"
```

# `r filename`
***
This script is a small data simulation to help figure out an appropriate data transformation withouth loosing too much statistical power in the subsequent regression analyses.

```{r initiate}
# define alternative package directory
r_on_server <- F # MANUAL EDIT! ARE YOU ON LOCAL R SESSION OR USING ONE OF THE IMISE SERVERS (E.G. FOROSTAR)?
if (r_on_server == T) {
  computer <- "forostar" # MANUAL EDIT! SEE THE FOLDER RIGHT BELOW FOR THE APPROPRIATE PACKAGE FOLDERS
  .libPaths(paste0("/mnt/ifs1_projekte/genstat/07_programme/rpackages/", computer))
}

# Packages for efficiently loading data
for (i in c(
  "knitr",
  "data.table",
  "MASS",
  "ggplot2",
  "scales",
  "CarlHelpR",
  "toolboxH"
)) {
  suppressPackageStartupMessages(library(i, character.only = TRUE))
}
```

# Data simulation and setup

```{r load}
# load the simuation results
newest.results <- newest_file(look_for = "SimulationResultsForSTEP2", subfolder = "results", print_full = T)
all.scenarios <- fread(newest.results)
```

# Exploratory plots

There are a few descisions that I need to make:
 * Bereiche or Quantile?
 * Best number of categories?
 * Performance compared with dichotomized glm?
 * Performance compared with Rank correlation?


Our best guess was, that grouping the metabolites into more categories than just 2 would result in the retaining of information and thus statistical power. These plots are supposed to illustrate the comparison between dichotomization and different versions of the proportional odds approach.

For the proportional odds model, the number of categories (`categnum`) and the way the categories were established (`categart`) vary. In this simulation, `r unique(all.scenarios$categnum)` were the number of categories tested.

For the data simulation, the parameters were the percentage of inflated zero-values (`proz0`) and the effekt size (`effekt`) varied. For each scenario, 5000 sampels were drawn. Each scenario was computed 1000 times. 

## Dichotomization vs. proportional odds model

First it needs to be established, whether the proportional odds approach performs better than dichotomization. Intuitively it should, but we can test this by plotting the p-values of the approaches against each other and observe their properties depending on the different parameters. 

This first plot, plotting all p-values only shows, that the the percentage of zero-inflated values has a high impact on the distribution depending on the effect size. For small effect-sizes, which are the most interesting for our study, a distinction seems difficult. However, the plot let's us hypothesize, that that the proportional odds model outperforms the dichotomization model with increasing effect-size and a lower percentage of zero-inflated values. 

```{r question.1.1, results='markup'}
# First question: Dicho vs Logit
# plot all dicho vs. prop odds pvals
p1 <- ggplot(all.scenarios, aes(-log10(dicho.pval),
                                -log10(logit.pval),
                                col = factor(proz0),
                                pch = categart,
                                size = categnum,
                                alpha = rev(categnum))) + 
  geom_point() +
  geom_abline(intercept = 0, slope = 1, lty = 2) + 
  facet_wrap(~effekt , scales = "free") + 
  scale_y_continuous(breaks = pretty_breaks(4)) +
  scale_x_continuous(breaks = pretty_breaks(4)) +
  scale_color_brewer(palette = "Set1") +
  theme_carl()

# plot dicho vs logit pvals
p1
```

Taking the average p-values over all realizations provides a clearer picture for the differences for small effect-sizes. The proportional odds approach clearly outperforms dichotomization. Only when the zero-inflation is as high as 80%, the performances are similar. The table shows the sum of p-values for each approach <= 0.05 for each combination of number of categories and type of category.

```{r question.1.2, results='markup'}
# plot mean (over realizations) dicho vs. prop odds pvals
# über realisationen mitteln für Übersichtlichkeit
test.1 <- all.scenarios[, lapply(.SD, mean), by = .(effekt, proz0, categart, categnum)]
p2 <- ggplot(test.1, aes(x = -log10(dicho.pval),
                         y = -log10(logit.pval),
                         col = factor(proz0),
                         pch = categart,
                         size = categnum,
                         alpha = rev(categnum))) + 
  geom_point() +
  geom_abline(intercept = 0, slope = 1, lty = 2) + 
  facet_wrap(~effekt , scales = "free") + 
  scale_y_continuous(breaks = pretty_breaks(4)) +
  scale_x_continuous(breaks = pretty_breaks(4)) +
  theme_carl()

# plot
# p2

# same as p2 but with different symbols etc.
p2.5 <- ggplot(test.1, aes(-log10(dicho.pval),
                   -log10(logit.pval),
                   col = categnum,
                   pch = categart,
                   size = proz0,
                   alpha = rev(factor(proz0)))) +
  geom_point() +
  facet_wrap(~effekt, scales = "free") +
  scale_x_continuous(breaks = pretty_breaks(4)) +
  scale_y_continuous(breaks = pretty_breaks(4)) +
  geom_abline(intercept = 0, slope = 1, lty = 2) +
  scale_color_distiller(palette="Spectral") +
  scale_alpha_manual(values = c(0.3, 0.5, 0.9)) + 
  theme_carl()
  
p2.5

# number of categories as deciding factor
kable(all.scenarios[ , lapply(.SD, function(x) sum(x <= 0.05)), by = .(categart,categnum),
                     .SDcols = c("linmod.pval.full.data",
                                 "linmod.pval.zero.inflated",
                                 "spearman.cor.pval.full.data",
                                 "spearman.cor.zero.inflated",
                                 "logit.pval",
                                 "dicho.pval")])
```

## Linear model vs. proportional odds model

Additionally we look at the performance of the prop-odds model against a linear model approach. We can see that the approaches compare in Terms of Power. The loss of information in the proportional odds approach pit against the violation of the normality-assumption of the linear model approach. 

```{r question.1.3, results='markup'}
# plot mean (over realizations) linmod vs. prop odds pvals
# how does logit model compare to linmod?
p3 <- ggplot(test.1, aes(x = -log10(linmod.pval.zero.inflated),
                         y = -log10(logit.pval),
                         col = factor(proz0),
                         pch = categart,
                         size = categnum,
                         alpha = rev(categnum))) + 
  geom_point() +
  geom_abline(intercept = 0, slope = 1, lty = 2) + 
  facet_wrap(~effekt , scales = "free") + 
  ggtitle(label = "P-value comparison", subtitle = "Zero-inflated data fit with proportional-odds model \nagainst zero-inflated data fit with linear model") +
  theme_carl()
p3
```

## Optimum for number of categories

Plotting the p-values against the number of categories reveals a maximum towards a higher number of categories. However, the slope might be distorted due to the higher amount of different categories <10. Looking at the categories >10 only reveals no increased model performance when the number of categories exeeds 10. Again, the interpretation of the results for small effect sizes proves difficult, but the data suggests no increasded power upwards of 10 categories. 

```{r question.2, results='markup'}
# second question: what number of categories is optimal?
# plot -log10(Pwert) against number of categories
p4 <- ggplot(test.1,
             aes(x = categnum,
                 y = -log10(logit.pval),
                 pch = categart,
                 color = factor(proz0))) +
  facet_wrap(~ effekt, scale = "free") +
  geom_smooth(method = "loess", aes(group = paste(factor(proz0), categart), lty = categart), alpha = 0.2, fullrange=T, span = 1.5) +
  geom_point(size = 2.5) +
  scale_x_continuous(breaks = pretty_breaks(4)) +
  scale_y_continuous(breaks = pretty_breaks(4)) +
  scale_color_brewer(palette = "Set1") +
  theme_carl()

# all categnum
p4

# large categories
p4.1 <- ggplot(test.1[categnum %in% c(7,8,9,10,20,30,40,50),],
             aes(x = categnum,
                 y = -log10(logit.pval),
                 pch = categart,
                 color = factor(proz0))) +
  facet_wrap(~ effekt, scale = "free") +
  geom_smooth(method = "loess", aes(group = paste(factor(proz0), categart), lty = categart), alpha = 0.2, fullrange = T, span = 1.5) +
  geom_point(size = 2.5) +
  scale_x_continuous(breaks = pretty_breaks(4)) +
  scale_y_continuous(breaks = pretty_breaks(4)) +
  scale_color_brewer(palette = "Set1") +
  theme_carl()

# only look at higher number of categories
p4.1

# look at categories 2:10
p4.2 <- ggplot(test.1[categnum %in% c(2:10,20), ],
             aes(x = categnum,
                 y = -log10(logit.pval),
                 pch = categart,
                 color = factor(proz0))) +
  facet_wrap(~ effekt, scale = "free") +
  geom_smooth(method = "loess", aes(group = paste(factor(proz0), categart), lty = categart), alpha = 0.2, fullrange = T, span = 1.5) +
  geom_point(size = 2.5) +
  scale_x_continuous(breaks = pretty_breaks(4)) +
  scale_y_continuous(breaks = pretty_breaks(4)) +
  scale_color_brewer(palette = "Set1") +
  theme_carl()

# only look at higher number of categories
p4.2
```

## Categories based on quantiles or range

The previous plots suggest that the categories based on quantiles perform better in terms of mean p-value for each category, which is again dependent on effect size and percentage of zero-inflation. Plotting the, averaged over all realizations of the model, -log10 p-values against each other reveal a slight advantage of quantile-defined categories, at least for larger effect sizes. For the effect sizes of 0.01 and 0.02 in 80% zero inflated data, no conclusion can be drawn from the data. However, the general trend of the simulation suggests a slight advantage of quantiles over ranges for subdividing the data into categories  

```{r question.3, results='markup'}
# third question: Bereiche oder Quantile
# plot bereiche ~ quantile pvals
test.2 <- dcast.data.table(data = test.1, formula = effekt + proz0 + categnum ~ categart, value.var = "logit.pval")
p5 <- ggplot(test.2,
       aes(x = -log10(bereiche),
           y = -log10(quantile),
           color = categnum,
           size = as.factor(proz0))) +
  facet_wrap(~effekt, scale = "free") + 
  geom_point(alpha = 1) +
  geom_abline(intercept = 0, slope = 1) + 
  scale_color_distiller(palette="Spectral") + 
  scale_alpha_manual(values = c(0.3,0.9))

p5
```

## Additional comparisons

Comparing the results of the, always fit with zero-inflated data, prop-odds model fit with the, either fit to the full or zero-inflated data set, rank correlation and linear model results The boxplots compare the p-value distribution of all approaches.  

```{r question.4.1.prep, results='markup'}
q_4 <- function(x,y) {
  p4 <- ggplot(test.1, aes(x = -log10(get(x)),
                           y = -log10(get(y)),
                           col = factor(proz0),
                           pch = categart,
                           size = categnum,
                           alpha = rev(categnum))) + 
    geom_point() +
    ylab(y) +
    xlab(x) +
    geom_abline(intercept = 0, slope = 1, lty = 2) +
    scale_color_brewer(palette="Set1") + 
    scale_alpha_continuous(range = c(0.3, 1)) +
    facet_wrap(~effekt , scales = "free") + 
    theme_carl()
  return(p4)
}
```

### Linear model and Spearman's correlation

First we check what influence the zero-inflation has on the linear model and spearman correlation power. We plot p-values of both approaches with the full and the zero-inflated data against each other. We can see that the the linear model sufferes more from the loss of data even at 20% of zero-values, while the rank correlation starts to suffer visibly at 50% zero-inflation.

```{r question.4.0}
p4.0.1 <- q_4(x = "linmod.pval.full.data", y = "linmod.pval.zero.inflated")
p4.0.1

p4.0.2 <- q_4(x = "spearman.cor.pval.full.data", y = "spearman.cor.pval.zero.inflated")
p4.0.2
```

Comparing between approaches shows the expected advantage of a linear model over rank correlation for the full data set. Zero-inflating the data evens the performance out. The violated normality assumption of the linear model should be considered when choosing between the approaches. A non-parametric approach like Spearman's rank correlation seems like the choice of reason. 

```{r question.4.1}
p4.1.2 <- q_4(x = "spearman.cor.pval.full.data", y = "linmod.pval.full.data")
p4.1.2

p4.1.1 <- q_4(x = "spearman.cor.pval.zero.inflated", y = "linmod.pval.zero.inflated")
p4.1.1
```

### Linear model and proportional odds model

While the optimal approach of fitting a linear model with the full data set remains superior to the prorportional odds model with zero-inflated data, the advantage all but disappears when fitting the linear model to the zero-inflated data. A small number of categories (<10), which leads to an increased loss of information for the proportional odds model visibly hurts the models performance. Otherwise, zero-inflation creates a level playing field for both models.

```{r question.4.2}
# do some tests
p4.2.1 <- q_4(x = "linmod.pval.full.data", y = "logit.pval")
p4.2.1

p4.2.2 <- q_4(x = "linmod.pval.zero.inflated", y = "logit.pval")
p4.2.2
```

### Spearman's correlation and proportional odds model

It is to be expected that Spearman's correlation of the full data set outperforms the zero-inflated proportional odds approach. Setting both approaches to the zero-inflated data against each other again only reveals an advantage of Spearman's correlation coefficient over a proportional odds model with very few (<10) categories. Otherwise the models perform equally.

```{r question.4.3}
p4.3.1 <- q_4(x = "spearman.cor.pval.full.data", y = "logit.pval")
p4.3.1

p4.3.2 <- q_4(x = "spearman.cor.pval.zero.inflated", y = "logit.pval")
p4.3.2
```

```{r question.4.4, include = F}
# boxplot
test.3 <- melt(data = all.scenarios,
               id.vars = c("effekt", "proz0", "categart", "categnum"),
               measure.vars = c("logit.pval",
                                "dicho.pval",
                                "linmod.pval.zero.inflated",
                                "linmod.pval.full.data",
                                "spearman.cor.pval.zero.inflated",
                                "spearman.cor.pval.full.data"))

# outer loop for proz0
lapply(unique(all.scenarios$proz0), function(y){
  
  # inner loop for effect size
  lapply(unique(all.scenarios$effekt), function(x){
    
    p7 <- ggplot(test.3[effekt == x & proz0 == y, ],
                 aes(y = -log10(value),
                     x = as.factor(categnum),
                     fill = variable)) +
      geom_boxplot() + 
      coord_flip() +
      facet_wrap( ~ categart) + 
      ggtitle(label = "Boxplot of Pvalues",
              subtitle = paste0("Effect-size = ", x, " and zero-inflation by ", y, "%")) +
      theme_minimal() +
      scale_fill_brewer(palette = "Spectral")
    
    p7
  })
})
```

## Comparison of effect sizes between linear model and proportional odds model

Plotting the average effect sizes from the linear model and the prop-odds model reveal a drastic overestimation of effect size with increasing effect size in the data by the prop-odds model. Additionally, the zero-inflation seems to be influencig seems to be adding to to this overestimation while leading to an underestimation of the added effect in the linear model.

```{r question.5}
p_8 <- function(x,y) {
  
  # define
  p8 <- ggplot(test.1,
         aes(x = get(x),
             y = get(y),
             size = categnum,
             col = factor(effekt),
             pch = categart,
             alpha = rev(factor(proz0)))) +
    geom_point() +
    geom_abline(intercept = 0, slope = 1, lty = 2, col = "black") +
    # facet_wrap( ~ , scales = "fixed") +
    scale_color_brewer(palette = "Set1") +
    ylab(y) +
    xlab(x) +
    scale_x_continuous(breaks = pretty_breaks(6)) +
    scale_y_continuous(breaks = pretty_breaks(9)) +
    scale_alpha_manual(values = c(0.3, 0.5, 0.9)) + 
    theme_carl()
  
  # plot
  p8
}

# define effect-size plot with zero-inflated linmod data
p8.1 <- p_8(x = "linmod.beta.zero.inflated",
             y = "logit.beta") + 
  ggtitle(label = "Beta estimate comparison", subtitle = "Zero-infalted prop-odds vs.\nzero-inflated data fit with lm")
p8.1

# define effect-size plot with zero-inflated linmod data
p8.2 <- p_8(x = "linmod.beta.full.data",
             y = "logit.beta") + 
  ggtitle(label = "Beta estimate comparison", subtitle = "Zero-infalted prop-odds vs.\n full data fit with lm")
p8.2
```

```{r save}
# write.table(x = all.scenarios,
#             file = paste0(pathwd, "/results/",
#                           format(Sys.time(), '%y%m%d'),
#                           "_SimulationResults.csv"),
#             sep = "\t", row.names = F)
```

```{r SessionInfo, echo=F, results='markup'}
sessionInfo()
```            